---
title: "nn_corr_multilevel_fisherz_resnet50"
author: "Anonymous"
date: "2023-06-16"
output: html_document
---


""" This notebook examines whether the correlation coefficients between
two metrics are statistically significant or not.

Factors: \* functionality: 1) ablation impact 2) decoding accuracy \*
metrics: 1) cka 2) mean_cca-Corr 3) mean_sq_cca_corr 4) procrustes 5)
pwcca

Methods:

-   linear model of correlation coefficient (different from 0), modeling
    random intercepts for class and layer
-   I use fisher z to transform these correlation coefficients into Z
    vlaues (normal distribution)
-   From that, we get the t-estimate, testing whether this is
    significant
-   Afterward, I plan to convert the B0 estimate back into an r value,
    which is interpretable.

TODO: concatenate all .csv files make sure that the factor information
is inserted into each """ \# load data \# calculate correlation \#
fisher z transform \# model mean cor value for class layer unit

## libraries
```{r load libraries, include=FALSE}
library(psych)
library(car)
library(lme4)
library(lmerTest)
library(plyr)
library(dplyr)
library(ggplot2)
library(rmarkdown)
library(readr)
library(yaml)
library(tidyverse)
library(GGally)
library(DescTools)
library(gghalves)
library(ggpubr)
library(extrafont)
library(gridExtra)
library(patchwork)
library(DescTools)
library(emmeans)
source("https://gist.githubusercontent.com/benmarwick/2a1bb0133ff568cbe28d/raw/fb53bd97121f7f9ce947837ef1a4c65a73bffb3f/geom_flat_violin.R")
main_dir <- dirname(getwd())
file.sources = list.files(file.path(main_dir, 'utils'),
                          pattern="*.R", 
                          full.names=TRUE, 
                          ignore.case=TRUE)
sapply(file.sources,source,.GlobalEnv)

```

```{r figure save parameters, message=FALSE, warning=FALSE}
font_import(pattern = "DejaVu", prompt = FALSE)
myFont <- "DejaVu Sans Mono"
w = 3
h = 1.8
units = c("in")
dpi = 600
scale = 2.5
```

# load data 
```{r concatenate dataframe}
main_dir <- dirname(getwd())
model = 'resnet50'
concat_df = data.frame()
  for (dv in c('resnet50_ablation_impact_X_cka', 
               'resnet50_ablation_impact_X_mean_cca_corr', 
               'resnet50_ablation_impact_X_mean_sq_cca_corr',
               'resnet50_ablation_impact_X_procrustes', 
               'resnet50_ablation_impact_X_pwcca',
               'resnet50_decoding_accuracy_delta_X_cka',
               'resnet50_decoding_accuracy_delta_X_mean_cca_corr',
               'resnet50_decoding_accuracy_delta_X_mean_sq_cca_corr',
               'resnet50_decoding_accuracy_delta_X_procrustes', 
               'resnet50_decoding_accuracy_delta_X_pwcca')) {
  print(dv)
  if (model == "alexnet") {
    data_fname <- file.path(main_dir, 'data', 'alexnet', paste0(dv, '.csv'))
  } else if (model == "mobilenet") {
    data_fname <- file.path(main_dir, 'data', 'mobilenet', paste0(dv, '-mobilenet.csv'))
  } else if (model == "resnet50") {
    data_fname <- file.path(main_dir, 'data', 'resnet50', paste0(dv, '.csv'))
  }
  
df <- read.csv(data_fname)
newdv <- sub("^resnet50_", "", dv)
df$functionality <- strsplit(newdv, '_X_')[[1]][1]
df$metric <- strsplit(newdv, '_X_')[[1]][2]
concat_df <- rbind(concat_df, df)
}

```

<!-- ## function -->
<!-- ```{r} -->
<!-- meanSummary <- function(DATA, GROUP, DV){ -->
<!--   z <- ddply(DATA, GROUP, .fun = function(xx){ -->
<!--                          c(mean_per_sub = mean(xx[,DV],na.rm=TRUE), -->
<!--                          sd = sd(xx[,DV],na.rm=TRUE) ) }) -->
<!--   return(z) -->
<!--   } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL, -->
<!--                            na.rm=FALSE, .drop=TRUE) { -->
<!--   ## Norms the data within specified groups in a data frame; it normalizes each -->
<!-- ## subject (identified by idvar) so that they have the same mean, within each group -->
<!-- ## specified by betweenvars. -->
<!-- ##   data: a data frame. -->
<!-- ##   idvar: the name of a column that identifies each subject (or matched subjects) -->
<!-- ##   measurevar: the name of a column that contains the variable to be summariezed -->
<!-- ##   betweenvars: a vector containing names of columns that are between-subjects variables -->
<!-- ##   na.rm: a boolean that indicates whether to ignore NA's -->
<!--     library(plyr) -->

<!--     # Measure var on left, idvar + between vars on right of formula. -->
<!--     data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop, -->
<!--      .fun = function(xx, col, na.rm) { -->
<!--         c(subjMean = mean(xx[,col], na.rm=na.rm)) -->
<!--       }, -->
<!--       measurevar, -->
<!--       na.rm -->
<!--     ) -->

<!--     # Put the subject means with original data -->
<!--     data <- merge(data, data.subjMean) -->

<!--     # Get the normalized data in a new column -->
<!--     measureNormedVar <- paste(measurevar, "_norm", sep="") -->
<!--     data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] + -->
<!--                                mean(data[,measurevar], na.rm=na.rm) -->

<!--     # Remove this subject mean column -->
<!--     data$subjMean <- NULL -->

<!--     return(data) -->
<!-- } -->
<!-- ``` -->


<!-- ```{r} -->
<!-- summarySE <- function(data = NULL, measurevar, groupvars = NULL, na.rm = FALSE, -->
<!--                       conf.interval = .95, .drop = TRUE) { -->
<!--   library(plyr) -->

<!--   # New version of length which can handle NA's: if na.rm==T, don't count them -->
<!--   length2 <- function(x, na.rm = FALSE) { -->
<!--     if (na.rm) { -->
<!--       sum(!is.na(x)) -->
<!--     } else { -->
<!--       length(x) -->
<!--     } -->
<!--   } -->

<!--   # This does the summary. For each group's data frame, return a vector with -->
<!--   # N, mean, median, and sd -->

<!--   datac <- plyr::ddply(data, groupvars, .drop=.drop, -->
<!--                    .fun = function(xx, col) { -->
<!--                        c(N      = length2(xx[[col]], na.rm=na.rm), -->
<!--                          mean   = mean(xx[[col]], na.rm=na.rm), -->
<!--                          median = median(xx[[col]], na.rm=na.rm), -->
<!--                          sd      = sd(xx[[col]], na.rm=na.rm) -->
<!--                        ) -->
<!--                    }, -->
<!--                    measurevar -->
<!--   ) -->

<!--   # Rename the "mean" and "median" columns -->
<!--  datac <- plyr::rename(datac, c("mean" = paste(measurevar, "_mean", sep = ""))) -->
<!--  datac <- plyr::rename(datac, c("median" = paste(measurevar, "_median", sep = ""))) -->

<!--  datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean -->

<!--   # Confidence interval multiplier for standard error -->
<!--   # Calculate t-statistic for confidence interval: -->
<!--   # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1 -->
<!--   ciMult <- qt(conf.interval / 2 + .5, datac$N - 1) -->
<!--   datac$ci <- datac$se * ciMult -->

<!--   return(datac) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r} -->
<!-- summarySEwithin <- function(data = NULL, measurevar, betweenvars = NULL, withinvars = NULL, -->
<!--                             idvar = NULL, na.rm = FALSE, conf.interval = .95, .drop = TRUE) { -->
<!-- #   """ -->
<!-- #   Summarizes data, handling within-subjects variables -->
<!-- #   by removing inter-subject variability. -->
<!-- #   It will still work if there are no within-S variables. -->
<!-- #   Gives count, un-normed mean, normed mean (with same between-group mean), -->
<!-- #   standard deviation, standard error of the mean, and confidence interval. -->
<!-- #   If there are within-subject variables, -->
<!-- #   calculate adjusted values using method from Morey (2008). -->

<!-- #   Parameters -->
<!-- #   ---------- -->
<!-- #   data: -->
<!-- #       a data frame. -->
<!-- #   measurevar: -->
<!-- #       the name of a column that contains the variable to be summariezed -->
<!-- #   betweenvars: -->
<!-- #       a vector containing names of columns that are between-subjects variables -->
<!-- #   withinvars: -->
<!-- #       a vector containing names of columns that are within-subjects variables -->
<!-- #   idvar: -->
<!-- #       the name of a column that identifies each subject (or matched subjects) -->
<!-- #   na.rm: -->
<!-- #       a boolean that indicates whether to ignore NA's -->
<!-- #   conf.interval: -->
<!-- #       the percent range of the confidence interval (default is 95%) -->
<!-- #       Ensure that the betweenvars and withinvars are factors -->
<!-- #   """ -->
<!--     library(raincloudplots) -->
<!--     factorvars <- vapply(data[, c(betweenvars, withinvars), drop = FALSE], -->
<!--         FUN = is.factor, FUN.VALUE = logical(1) -->
<!--     ) -->

<!--     if (!all(factorvars)) { -->
<!--         nonfactorvars <- names(factorvars)[!factorvars] -->
<!--         message( -->
<!--             "Automatically converting the following non-factors to factors: ", -->
<!--             paste(nonfactorvars, collapse = ", ") -->
<!--         ) -->
<!--         data[nonfactorvars] <- lapply(data[nonfactorvars], factor) -->
<!--     } -->

<!--     # Get the means from the un-normed data -->
<!--     datac <- summarySE(data, measurevar, -->
<!--         groupvars = c(betweenvars, withinvars), -->
<!--         na.rm = na.rm, conf.interval = conf.interval, .drop = .drop -->
<!--     ) -->

<!--     # Drop all the unused columns (these will be calculated with normed data) -->
<!--     datac$sd <- NULL -->
<!--     datac$se <- NULL -->
<!--     datac$ci <- NULL -->

<!--     # Norm each subject's data -->
<!--     ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop = .drop) -->

<!--     # This is the name of the new column -->
<!--     measurevar_n <- paste(measurevar, "_norm", sep = "") -->

<!--     # Collapse the normed data - now we can treat between and within vars the same -->
<!--     ndatac <- summarySE(ndata, measurevar_n, -->
<!--         groupvars = c(betweenvars, withinvars), -->
<!--         na.rm = na.rm, conf.interval = conf.interval, .drop = .drop -->
<!--     ) -->

<!--     # Apply correction from Morey (2008) to the standard error and confidence interval -->
<!--     #  Get the product of the number of conditions of within-S variables -->
<!--     nWithinGroups <- prod(vapply(ndatac[, withinvars, drop = FALSE], -->
<!--         FUN = nlevels, -->
<!--         FUN.VALUE = numeric(1) -->
<!--     )) -->
<!--     correctionFactor <- sqrt(nWithinGroups / (nWithinGroups - 1)) -->

<!--     # Apply the correction factor -->
<!--     ndatac$sd <- ndatac$sd * correctionFactor -->
<!--     ndatac$se <- ndatac$se * correctionFactor -->
<!--     ndatac$ci <- ndatac$ci * correctionFactor -->

<!--     # Combine the un-normed means with the normed results -->
<!--     df <- merge(datac, ndatac) -->
<!--     return(df) -->
<!-- } -->
<!-- ``` -->



1)  transformed mean_cca_corr mean_sq_cca_corr inverse
2)  fisher z for correlations
3)  within class/functionality/layers
4)  average


```{r reverse code and contrast code}
concat_df = concat_df %>% mutate(corr_transform = ifelse(metric == "mean_cca_corr" | metric == "mean_sq_cca_corr", -1 * correlation, correlation))
```


# main effect of functionality
```{r raincloudplots main effect of functionality}
# parameters __________________________________________________________________
model = 'resnet';    model_keyword = "resnet"
subjectwise_mean = "mean_per_sub"; group_mean = "mean_per_sub_norm_mean"
iv = "func"
ylim = c(-.25, 1)
se = "se"
subject = "class"
ggtitle = paste0(model_keyword,
                 " :: Functionality, averaged across layers and classes")
legend_title = "Functionality"
xlab = "Functionality "
ylab = "Correlation between \nmetric and functionality"
dv_keyword = "corr"

# within-class summary statistics ______________________________________________
classwise <- meanSummary(average_fisherz,
                         c(subject, iv), "corr_z")

groupwise <- summarySEwithin(
  data = classwise,
  measurevar = "mean_per_sub",
  withinvars = "func",
  idvar = "class"
)

subjectwise = classwise
color <- c("#D73027", "#4575B4")

# ggplot ______________________________________________________________________
p1 <- ggplot(data = subjectwise,
            aes(
              y = .data[[subjectwise_mean]],
              x = factor(.data[[iv]]),
              fill = factor(.data[[iv]])
            )) +
  
  geom_half_violin(
    aes(fill = factor(.data[[iv]])),
    side = 'r',
    position = 'dodge',
    adjust = 1.5,
    trim = FALSE,
    alpha = .3,
    colour = NA
  ) +
  
  geom_line(data = subjectwise,
    aes(
      group = .data[[subject]],
      x = as.numeric(.data[[iv]]) - .15,
      y = .data[[subjectwise_mean]],
      fill = factor(.data[[iv]])
      ),
    linetype = "solid",
    color = "grey",
    alpha = .3) +

  geom_point(
    aes(
      x = as.numeric(.data[[iv]]) - .15,
      y = .data[[subjectwise_mean]],
      color = factor(.data[[iv]])
    ),
    position = position_jitter(width = .05),
    size = 2,
    alpha = 0.8,
    
  ) +
  
  geom_half_boxplot(
    aes(x = .data[[iv]],
        y = .data[[subjectwise_mean]],
        fill = .data[[iv]]),
    side = "r",
    outlier.shape = NA,
    alpha = 0.8,
    width = .1,
    colour = "black",
    errorbar.draw = FALSE
  ) +
  
  # legend stuff ________________________________________________________
  
  guides(color = "none") +
  guides(fill = guide_legend(title = legend_title)) +
  scale_fill_manual(values = color) +
  scale_color_manual(values = color) +
  ggtitle(ggtitle) +
  scale_x_discrete(
    labels = c(
      "ablation_impact" = "Network performance deficits",
      "decoding_accuracy_delta" = "Decoding accuracy deficits"
    )
  ) +
  xlab(xlab) +
  ylab(ylab) +
  ylim(ylim) +
  theme_bw() + theme_classic2() +
  theme(aspect.ratio = 6 / 10) +
  theme(legend.position = "none",
        text = element_text(family = "DejaVu Sans"), 
        plot.title = element_text(size=12))

save_fname <-
  file.path(main_dir, 'figure', model,
            paste0(model, '01_iv-', iv, '_dv-', dv_keyword, '.png'))
w = 3
ggsave(
  save_fname,
  width = w,
  unit = "in",
  dpi = 600,
  scale = 2.5
)
p1
```


# check nan values
```{r}
# check nan
rows_with_nans <- apply(average_fisherz, 1, function(row) any(is.na(row)))

# Print the rows with NaNs
print(average_fisherz[rows_with_nans, ])

# Remove rows with NaN values
average_fisherz_dropna <- average_fisherz[complete.cases(average_fisherz), ]

# Print the resulting dataframe
print(average_fisherz_dropna)
```
# main effect of metric


1)  transformed mean_cca_corr mean_sq_cca_corr inverse
2)  fisher z for correlations
3)  within class/functionality/layers
4)  average


```{r reverse code and contrast code}
concat_df = concat_df %>% mutate(corr_transform = ifelse(metric == "mean_cca_corr" | metric == "mean_sq_cca_corr", -1 * correlation, correlation))
```


```{r fisher z transform}
N <- concat_df %>%
  group_by(class ,metric, functionality)  %>%
  mutate(fisherz = DescTools::FisherZ(corr_transform))
average_fisherz <- meanSummary(N,
                         c("class", "metric", "functionality"), "fisherz")
average_fisherz$fisherz <- average_fisherz$mean_per_sub
average_fisherz$corr_z = DescTools::FisherZInv(average_fisherz$fisherz)
average_fisherz$func_con[average_fisherz$functionality == "ablation_impact"] <- -0.5
average_fisherz$func_con[average_fisherz$functionality == "decoding_accuracy_delta"] <- 0.5

average_fisherz$func  = factor(average_fisherz$functionality)
average_fisherz$metric_ordered <- factor(average_fisherz$metric, 
                                   levels=c( "mean_cca_corr", "mean_sq_cca_corr","pwcca", "cka", "procrustes"))
average_fisherz$metric_con  = factor(average_fisherz$metric_ordered)

contrasts(average_fisherz$metric_con) = contr.helmert(5)
# check nan
rows_with_nans <- apply(average_fisherz, 1, function(row) any(is.na(row)))
print(average_fisherz[rows_with_nans, ])
average_fisherz_dropna <- average_fisherz[complete.cases(average_fisherz), ]
print(average_fisherz_dropna)
```



# Multilevel modeling
```{r multilevel modeling }
full = lmer(corr_z ~ func_con * metric_con + (1|class)   , data = average_fisherz_dropna)
summary(full)
```

## Omnibus results
```{r}
Anova(full, type = "III", test.statistic = "F")
```
# simple effects
```{r}
library(emmeans)
# emmeans(full, list(pairwise ~ metric_con* func_con), adjust = "tukey")
library(emmeans)
emm1 = emmeans(full, specs =  ~ metric_con* func_con)

cka_mean = c(0,0,0,1/2,0, 0,0,0,1/2,0)
procrustes_mean = c(0,0,0,0,1/2, 0,0,0,0,1/2)

cka_mean_causal = c(0,0,0,1/2,0, 0,0,0,0,0)
procrustes_mean_causal = c(0,0,0,0,1/2, 0,0,0,0,0)

cka_mean_noncausal = c(0,0,0,0,0, 0,0,0,1/2,0)
procrustes_mean_noncausal = c(0,0,0,0,0, 0,0,0,0,1/2)

cca_mean = c(1/6, 1/6, 1/6, 0, 0, 1/6, 1/6, 1/6, 0, 0)
cka_pro = c(0,0,0,1/4,1/4, 0,0,0,1/4,1/4)

cca_mean_causal = c(1/3, 1/3, 1/3, 0, 0,0,0,0,0,0)
cka_pro_causal = c(0,0,0,1/2,1/2,0,0,0,0,0)

cca_mean_noncausal = c(0,0,0,0,0,1/3, 1/3, 1/3, 0, 0)
cka_pro_noncausal = c(0,0,0,0,0,  0,0,0,1/2,1/2)

int = c(1,1,1,1,1,-1,-1,-1,-1,-1)
contrast(emm1, method = list("cka/procrustes vs. mean_cca/mean_sq/pwcca on average" = cka_pro - cca_mean, 
                             "procrustes vs. cka on average" = procrustes_mean - cka_mean,
                             "procrustes vs. cka causal" = procrustes_mean_causal - cka_mean_causal,
                             "procrustes vs. cka noncausal" = procrustes_mean_noncausal - cka_mean_noncausal,
                             "within causal, cka/procrustes vs. mean_cca/mean_sq/pwcca" =  cka_pro_causal - cca_mean_causal,
                             "within noncausal, cka/procrustes vs. mean_cca/mean_sq/pwcca" = cka_pro_noncausal - cca_mean_noncausal,
                             "interaction, cka/procrustex vs. cca vs. functionality" = (cka_pro_causal - cca_mean_causal) - (cka_pro_noncausal - cca_mean_noncausal) ) )

```

# ggplot main effect of metric
```{r barplot metric}
# parameters __________________________________________________________________
metric_classwise <- meanSummary(
        average_fisherz,
        c("class","metric_con"), "corr_z"
    )

metric_groupwise <- summarySEwithin(
        data = metric_classwise,
        measurevar = "mean_per_sub", # variable created from above
        withinvars = c( "metric_con"), # iv
        idvar = "class"
    )

subjectwise = metric_classwise
groupwise = metric_groupwise
subjectwise_mean = "mean_per_sub"
group_mean = "mean_per_sub_norm_mean"
iv = "metric_con"
ylim = c(0, 1)
se = "se"
subject = "class"
ggtitle = paste0(model_keyword, " :: Metrics, averaged across layers and classes")
legend_title = "metric"
xlab = "Metric"
ylab = "Correlation between \nmetric and functionality"
iv_keyword = "metric"
dv_keyword = "corr"

if (any(startsWith(dv_keyword, c("expect", "Expect")))) {
  color <- c("#464655", "#898983","#B6B6C1", "#CECEE0", "#DEDEEF")
} else {
  color <- c( "#000000","#2D0040", "#5A0080","#8600BF","#B300FF")
}

# ggplot ______________________________________________________________________
p2 <- ggplot(data = subjectwise,
            aes(
              y = .data[[subjectwise_mean]],
              x = factor(.data[[iv]]),
              fill = factor(.data[[iv]])
            )) +
  geom_half_violin(
    aes(fill = factor(.data[[iv]])),
    side = 'r',
    position = 'dodge',#position_nudge(x = .1, y = 0),
    adjust = 1.5,
    trim = TRUE,
    alpha = .3,
    colour = NA
  ) +
  
  geom_point(
    aes(
      x = as.numeric(factor(.data[[iv]])) - .15 ,
      y = .data[[subjectwise_mean]],
      color = factor(.data[[iv]])
    ),
    position = position_jitter(width = .05),
    size = 2,
    alpha = 0.8,
  ) +
  
  geom_half_boxplot(
    aes(x = .data[[iv]],
        y = .data[[subjectwise_mean]],
        fill = .data[[iv]]),
    side = "r",
    outlier.shape = NA,
    alpha = 0.8,
    width = .2,
    colour = "black",
    notch = FALSE,
    notchwidth = 0,
    varwidth = FALSE, 
    errorbar.draw = FALSE
  ) +
  
  
  # legend stuff ________________________________________________________ # nolint

  guides(fill = guide_legend(override.aes = list(shape = 20, size = 1, alpha = 1))) +
           theme(legend.title = legend_title) +
  scale_shape(guide=FALSE) +
  scale_fill_manual(values = color) +
  scale_color_manual(values = color) +
  ggtitle(ggtitle) +
  xlab(xlab) +
  ylab(ylab) +
  ylim(ylim) +
  theme_bw() + theme_classic2() +
  theme(axis.text.x = element_text(
    angle = 30,
    vjust = 1,
    hjust = 1
  )) +
  theme(aspect.ratio = 6 / 10) +
  theme(legend.position = "none",
        text = element_text(family = "DejaVu Sans"), 
        plot.title = element_text(size=12))
save_fname <-
  file.path(main_dir, 'figure', model,
            paste0(model, '02_iv-', iv_keyword, '_dv-', dv_keyword, '.png'))
ggsave(
  save_fname,
  width = w,
  #height = h,
  unit = "in",
  dpi = 600,
  scale = 2.5
)

p2
```


# ggplot interaction (function x metric)
```{r raincloudplots interaction}
library(gghalves)

# parameters __________________________________________________________________
average_fisherz_dropna$func = average_fisherz_dropna$functionality
int_unitwise <- meanSummary(
        average_fisherz_dropna,
        c("class", "func", "metric_ordered"), "corr_z"
    )

int_groupwise <- summarySEwithin(
        data = int_unitwise,
        measurevar = "mean_per_sub", # variable created from above
        withinvars = c("func", "metric_ordered"), # iv
        idvar = "class"
    )

subjectwise = int_unitwise
subjectwise$metric_ordered <- factor(
  subjectwise$metric_ordered,
  levels = c( "mean_cca_corr", "mean_sq_cca_corr","pwcca", "cka", "procrustes"
              )
)
subjectwise$varint <-
  as.factor(paste(subjectwise$metric_ordered, subjectwise$func))
subjectwise$varint <- factor(
  subjectwise$varint,
  levels =  c(
     "mean_cca_corr ablation_impact", "mean_sq_cca_corr ablation_impact", "pwcca ablation_impact", "procrustes ablation_impact", "cka ablation_impact",
     "mean_cca_corr decoding_accuracy_delta", "mean_sq_cca_corr decoding_accuracy_delta", "pwcca decoding_accuracy_delta", "procrustes decoding_accuracy_delta", "cka decoding_accuracy_delta"
  )
)
groupwise = int_groupwise
iv1 = "func"
iv2 = "metric_ordered" 
sub_mean = "mean_per_sub" 
group_mean = "mean_per_sub_norm_mean" 
se = "se" ; subject = "class"
ggtitle = paste0(model_keyword," :: Interaction of functionality and metric" )

legend_title = "Layer"
xlab = "Functionality"
ylab = "Correlation between metric and functionality"
iv_keyword = "funcXmetric"
dv_keyword = "corr"

int_color = c(
  "#000000",   "#3F0005",   "#7D000B",   "#BC0010",   "#FA0015",
   "#000000",   "#00003F",   "#00007D",   "#0000BC",   "#0000FA"
)

bw_color = c("#0F0F0F", "#494949", "#838383", "#BDBDBD", "#F7F7F7", "#BDBDBD", "#F7F7F7","#838383", "#BDBDBD", "#BDBDBD")
p3 <- ggplot(data = subjectwise,
            aes(y = .data[[sub_mean]],
                x = .data[[iv1]],
                fill =varint,
                width=.9)) +
  geom_half_violin(
    aes(fill = varint),#.data[[iv2]]),
    position = position_nudge(x = .1, y = 0),
    adjust = 1.5,
    trim = FALSE,
    alpha = 0,
    colour = NA
  ) +

  geom_point(
    data = subjectwise,
    aes(
      x = .data[[iv1]],
      y = .data[[sub_mean]],
      color = varint
    ),
    position = position_jitterdodge(), 
    size = 2,
    alpha = 0.8,
    shape = 20, 
    show.legend=FALSE
  ) +

  geom_half_boxplot(
    data = subjectwise,
    aes(x = .data[[iv1]],
        y = .data[[sub_mean]],
        fill = varint),
    side = "r",
    outlier.shape = NA,
    alpha = 0.8,
    width = .8,
    colour = "black",
    notch = FALSE,
    notchwidth = 0,
    varwidth = FALSE,
    errorbar.draw = FALSE,
    center = TRUE,
    show.legend=TRUE
  ) +

  # legend stuff __________________________________________________________________________________ # nolint

  scale_fill_manual(values = int_color, name = "metric", guide = "none") +
  scale_color_manual( values = int_color, name = "metric", guide = "none") +

  guides(fill = "none") +
  guides(color = "none") +
  ggtitle(ggtitle) +
  xlab(xlab) +
  ylab(ylab) +
    scale_x_discrete(
    labels = c(
      "ablation_impact" = "Network performance deficits",
      "decoding_accuracy_delta" = "Decoding accuracy deficits"
    )
  ) +

  theme_bw() + theme_classic2() +
    #theme(aspect.ratio=4/6) 
theme(aspect.ratio = 6 / 10) +
  theme(legend.position = "none",
        text = element_text(family = "DejaVu Sans"), 
        plot.title = element_text(size=14))


p3

p3
save_fname <-
  file.path(main_dir, 'figure', model,
            paste0(model, '03_iv-', iv_keyword, '_dv-', dv_keyword, '.png'))


ggsave(
  save_fname,
  plot = p3,
  width = 3,
  #height = h,
  unit = "in",
  dpi = 600,
  scale = 2.5)
```



# contrast code CKA/Procrustes vs CCA
```{r}
average_fisherz$func_con[average_fisherz$functionality == "ablation_impact"] <- -0.5
average_fisherz$func_con[average_fisherz$functionality == "decoding_accuracy_delta"] <- 0.5


average_fisherz$metric_cca[average_fisherz$metric == "cka"] <- 0.5
average_fisherz$metric_cca[average_fisherz$metric == "procrustes"] <- 0.5
average_fisherz$metric_cca[average_fisherz$metric == "mean_cca_corr"] <- -0.5
average_fisherz$metric_cca[average_fisherz$metric == "mean_sq_cca_corr"] <- -0.5
average_fisherz$metric_cca[average_fisherz$metric == "pwcca"] <- -0.5

average_fisherz$func  = factor(average_fisherz$functionality)
model.cca = lmer(corr_z ~ func_con * metric_cca + (1|class)  , data = average_fisherz)
summary(model.cca)
```


# contrast code CKA/Procrustes vs CCA
```{r}
average_fisherz$func_con[average_fisherz$functionality == "ablation_impact"] <- -0.5
average_fisherz$func_con[average_fisherz$functionality == "decoding_accuracy_delta"] <- 0.5


average_fisherz$metric_cca[average_fisherz$metric == "cka"] <- 0.5
average_fisherz$metric_cca[average_fisherz$metric == "procrustes"] <- 0.5
average_fisherz$metric_cca[average_fisherz$metric == "mean_cca_corr"] <- -0.5
average_fisherz$metric_cca[average_fisherz$metric == "mean_sq_cca_corr"] <- -0.5
average_fisherz$metric_cca[average_fisherz$metric == "pwcca"] <- -0.5

average_fisherz$func  = factor(average_fisherz$functionality)
model.cca = lmer(corr_z ~ func_con * metric_cca + (1|class)  , data = average_fisherz)
summary(model.cca)
```
